================class 11======================

Autoscaling
===========
==> Process of increasing / decreasing infrastructure resources based on the demand (traffic, memory, CPU)

==> Types of Scaling

1.Horizontal Scaling
=> Adding more servers/instances/Pods ( 3 pods --> 6 pods )
Scale Out --> increasing servers/ pods
Scale In --> reduces resources( 6 pods --> 2 pods )

HPA(Horizontal Pod Autoscaler)

2.Vertical Scaling
=> Increases resources of same system ( instead of 2 CPU, give 4 CPUs, 4GB RAM --> 8GB)
Scale UP --> Increases capacity of same server
Scale Down --> Reducing resource of same system

Note : In Kubernetes, vertical scaling is less common bcz Pods are meant to be lightweight but you can do Vertical Pod Autoscaler(VPA)


Kubernetes Metric Server --> also called Heapster
=========================
It is used for monitoring the overall health and performance of k8s cluster, providing data needed for Kubernetes feature like HPA.

Note : Metrics Server will not be present by default in k8s cluster

HPA will interact with Metric Server to identify CPU/Memory utilization of POD

==> This metric server in k8s will collect info like cpu, ram etc for all pods and nodes in the cluster

==> kubelet in k8s cluster periodically collects resource usage statistics from the node and containers running on it and metric server collects these metrics from kubelet

Install Metric server

$ kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

after 1 minute
$ kubectl get deployment -n kube-system | grep metrics

# Try metrics
kubectl top nodes
kubectl top pods

$ vi auto-scale.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-deployment
  labels:
    app: telusko
spec:
  replicas: 3
  selector:
    matchLabels:
      app: telusko
  template:
    metadata:
      labels:
        app: telusko
    spec:
      containers:
      - name: cont1
        image: hacker123shiva/springbt-in-docker:latest
        resources:
            requests:
              cpu: "100m"  # Add this line
              # Optional: Add a memory request too
              memory: "128Mi"


$ kubectl apply -f auto-scale.yml

$ kubectl get pods


To implement HPA
$ kubectl autoscale deployment product-deployment --cpu=20% --min=2 --max=10

$ kubectl get pods --watch

$ kubectl get hpa
$ kubectl get pods

$ kubectl debug -it <pod-name> --image=ubuntu:latest --target=cont1 --share-processes

$ kubectl debug -it product-deployment-6d49bfcf78-kzsc9 --image=ubuntu:latest --target=cont1 --share-processes

apt update
apt install -y stress


stress --cpu 8 --io 1 --vm 2 --vm-bytes 128M --timeout 60s

$ vi hpa.yml

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: product-deployment-hpa
spec:
  # This tells the HPA what resource to scale
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: product-deployment # Must match your Deployment's name

  # Define the minimum and maximum number of pods
  minReplicas: 2
  maxReplicas: 10

  # Define the metrics that will trigger scaling actions
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        # Type of target: Utilization is a percentage of the defined resource request
        type: Utilization
        # Target average utilization across all pods is 20%
        averageUtilization: 20

$ kubectl get pods

$ kubectl debug -it <pod-name> --image=ubuntu:latest --target=cont1 --share-processes

$ kubectl debug -it product-deployment-6d49bfcf78-kzsc9 --image=ubuntu:latest --target=cont1 --share-processes

apt update
apt install -y stress


stress --cpu 8 --io 1 --vm 2 --vm-bytes 128M --timeout 60s



================
Resource Quota
==============

==> Kubernetes cluster can be divided into namespaces 

==> The Pods in k8s will run with no limitation of Memory and CPU by default

==> We can give limit for Pod (Set limits to CPU, Memory, storage)

==> 1000 milliCPUs = 1CPU

================
create namespace
$ kubectl create ns dev

$ kubectl get ns

Switch to dev name space
$ kubectl config set-context --current --namespace=dev

To see which name space i am in
$ kubectl config view


Create resource quota

$ vi dev-quota.yml

apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    pods: "5"
    limits.cpu: "1"
    limits.memory: 1Gi

$ kubectl apply -f dev-quota.yml

To see quota

$ kubectl get quota

$ vi deploy.yml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-deployment
  labels:
    app: telusko
spec:
  replicas: 3
  selector:
    matchLabels:
      app: telusko
  template:
    metadata:
      labels:
        app: telusko
    spec:
      containers:
      - name: cont1
        image: hacker123shiva/springbt-in-docker:latest
        resources:
          limits:
            cpu: "1"
            memory: 512Mi
...
$ kubectl apply -f deploy.yml

$ kubectl get pods

==> You will notice only 1 pod is running bcz the namespace the max CPU is 1 and 1 pod is using 1cpu

$ kubectl delete -f deploy.yml

==> If you want to see 3 pods then modify deploy.yml resource 

        resources:
          limits:
            cpu: "0.3"
            memory: 300Mi

==> kubectl apply -f deploy.yml

$ kubectl get pods

You will see 3 pods creating 

$ kubectl delete -f deploy.yml

kubectl config set-context --current --namespace=default
=========================================

Persistent Volume (PV)
======================
==> If we delete pod , data is also lost , bcz data is stored locally on the pod == Stateless
==> If we delete pod, and data in pod is persistent == Stateful (We can store the data in external storage like AWS EBS ..) 


K8S Persistent Volume helps us to manage storage for application(pods) running in k8s cluster

Persistent Volume are independent of pods and they can exists even if pods are not using them













